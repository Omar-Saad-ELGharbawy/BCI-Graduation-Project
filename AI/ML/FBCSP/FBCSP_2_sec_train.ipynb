{"cells":[{"cell_type":"markdown","metadata":{"id":"xgdH4QWHulUz"},"source":["# Importing packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vA3H342ptnzP","outputId":"e4895d03-693f-4fc6-b940-7d4de999c06f"},"outputs":[],"source":["# !pip install mne"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nI3ejojr869-","outputId":"36a5cf4f-d238-44b6-dd83-c5ad3ad663d6"},"outputs":[],"source":["# !pip install pyxdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiCKgVOiuiZB"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import mne\n","import pyxdf\n","import glob\n","import os\n","import matplotlib.pyplot as plt\n","from scipy.io import loadmat\n","import scipy\n","import sklearn\n","# ------------------------------------------------------------------------------------------\n","from sklearn.preprocessing import LabelEncoder,StandardScaler\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda\n","from sklearn.model_selection import ShuffleSplit, cross_val_score, train_test_split, GridSearchCV, StratifiedShuffleSplit\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import LinearSVC, SVC\n","\n","# ------------------------------------------------------------------------------------------\n","from mne.decoding import CSP\n","from mne import Epochs, pick_types\n","from mne.channels import make_standard_montage\n","from mne.datasets import eegbci\n","from mne.io import concatenate_raws, read_raw_edf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTEZcXAdcFRT"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neural_network import MLPClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbHq0T0XcFRU"},"outputs":[],"source":["from FBCSP_V5 import FBCSP_V5 as FBCSP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vefLh0o2ukU2"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore') # to ignore warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AczJm-EVKkcq"},"outputs":[],"source":["verbose = False                    # global variable to suppress output display of MNE functions\n","mne.set_log_level(verbose=verbose) # to suppress large info outputs"]},{"cell_type":"markdown","metadata":{"id":"qYSAnVtxusG5"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Put subject name here for saving path \n","sub_name = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkE9AxdIPZx3","outputId":"aff29126-9c29-4ea2-e413-1d9b2ac3cb81","tags":["Paths"]},"outputs":[],"source":["# Put your path here\n","data_path = \"\" \n","folder_path = data_path\n","files   = glob.glob(folder_path + '/*eeg.xdf')\n","# files   = glob.glob(folder_path)\n","len(files)     # if  return zero,then no file is loaded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Llvr3JRMcFRX"},"outputs":[],"source":["# files.sort()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciCkti80tTje","outputId":"d20d011c-618d-472d-c0f2-0ebeae13a918"},"outputs":[],"source":["files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5Q223s8cFRX","outputId":"d6780b0d-522b-41cb-ceee-0d3123cd0793"},"outputs":[],"source":["# Filter the paths\n","filtered_paths = [path for path in files if ('Right Grasp' in path or 'Right Release' in path) and\n","                                            ('B_Right Grasp' not in path and 'B_Right Release' not in path)]\n","\n","# filtered_paths = [path for path in files if ('Right Grasp' in path or 'Right Release' in path or 'Baseline' in path) and\n","#                                             ('B_Right Grasp' not in path and 'B_Right Release' not in path and 'B_Baseline' not in path)]\n","\n","# Print the number of filtered paths and the paths themselves\n","print(f'Number of filtered paths: {len(filtered_paths)}')\n","filtered_paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLmo38MMoZh0","outputId":"62e332d7-f16f-4082-d8d7-40c5dc7f5cc5"},"outputs":[],"source":["all_files = filtered_paths\n","len(all_files)"]},{"cell_type":"markdown","metadata":{"id":"Bpe1FMFI9HBC"},"source":["# from XDF to MNE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RJZO_2ri6xS"},"outputs":[],"source":["# read stream from xdf\n","streams, header = pyxdf.load_xdf(all_files[0])\n","# extract data\n","data = streams[0][\"time_series\"].T\n","# check that it is 9 channels\n","# assert data.shape[0] == 9 # 9 raw EEG channels\n","\n","#get channels count\n","ch_count = int(streams[0][\"info\"][\"channel_count\"][0])\n","# extract channels names\n","# ch_names = []\n","# for i in range(ch_count):\n","#   ch_names.append(streams[0][\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"][i][\"label\"][0])\n","# extract sampling ratw\n","fs = float(streams[0][\"info\"][\"nominal_srate\"][0])\n","# create info\n","# info = mne.create_info(ch_names, fs, \"eeg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdTPbcC7TZyI"},"outputs":[],"source":["# extract channels names\n","ch_names = []\n","for i in range(ch_count):\n","  ch_name = streams[0][\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"][i][\"label\"][0]\n","  # ch_name= ch_name.split(\"\\n\")[1]\n","  ch_name= ch_name.split(\"\\n\")[0]\n","  ch_names.append(ch_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFJ3pr7CTk8c","outputId":"c463998b-69d8-4f73-d6b3-c775b00e822b"},"outputs":[],"source":["ch_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6mwiszhwTY8_"},"outputs":[],"source":["# info = mne.create_info(crack_channel_names, fs, \"eeg\")\n","info = mne.create_info(ch_names, fs, \"eeg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xY_sgMNIkkQu"},"outputs":[],"source":["def extract_tasks_names(files):\n","  task_names = []\n","  for path in files:\n","      # Split the path to isolate the filename\n","      filename = path.split('/')[-1]\n","      # Extract the task name part\n","      task_name = filename.split('_')[-3]\n","      # Replace the hyphen with a space to match the desired format\n","      task_name = task_name.split('-')[-1]\n","      # Append the task name to the list\n","      task_names.append(task_name)\n","      # one more t imefor dupli catio n\n","      task_names.append(task_name)\n","  return task_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8sLrWnLcFRZ","outputId":"728d0f66-73d4-425c-fef3-b52d8e8b094e"},"outputs":[],"source":["task_names = extract_tasks_names(all_files)\n","print(len(task_names))\n","task_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85Bi8oRucFRZ"},"outputs":[],"source":["# # List to store all task names\n","# all_task_names = []\n","# all_task_names.extend(task_names * 2)  # Duplicate the task names\n","# print(all_task_names)\n","# print(len(all_task_names))\n","# all_task_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtKrh6oicFRZ","outputId":"dd704a3c-ffa1-4fea-8aea-bc53ca3c13a3"},"outputs":[],"source":["set(task_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdVQjkn0QbJJ","outputId":"8e79dd24-e8d2-4c08-ca0d-e1a915896242"},"outputs":[],"source":["# event_id = {'Left_Grasp': 1, 'Right_Grasp': 2, 'Right_Release': 3, 'Baseline': 4}\n","event_id = {'Right Grasp': 1, 'Right Release': 2, 'Baseline': 3}\n","# Convert the list of task names to the list of numbers\n","task_numbers = [event_id[task] for task in task_names]\n","print(task_numbers)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jO3bhObAwVnD","outputId":"2e70218d-2635-4d77-86cf-5944590da8f6"},"outputs":[],"source":["print(len(task_names))\n","# task_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMTLdmt4cFRa","outputId":"55ef6153-91c5-4b60-9ade-5e9b60ccf897"},"outputs":[],"source":["# List to store shapes of all data arrays\n","shapes = []\n","\n","for fname in all_files:\n","    streams, header = pyxdf.load_xdf(fname)\n","    data = streams[0][\"time_series\"].T\n","    shapes.append(data.shape)\n","    # print(data.shape)\n","\n","# Calculate the minimum shape\n","min_rows = min(shape[0] for shape in shapes)\n","min_cols = min(shape[1] for shape in shapes)\n","\n","print(f\"The minimum shape is: ({min_rows}, {min_cols})\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7o98Cw7cFRa"},"outputs":[],"source":["# all_data=[]\n","# for fname in all_files:\n","#     streams, header = pyxdf.load_xdf(fname)\n","#     data = streams[0][\"time_series\"].T\n","#     print(data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJm_lBs_bHw6"},"outputs":[],"source":["# crop parametes\n","t_1_start = 1\n","t_1_end = 3\n","\n","idx_1_start = int(fs*t_1_start)\n","idx_1_end = int(fs*t_1_end)\n","\n","t_2_start = 3\n","t_2_end = 5\n","idx_2_start = int(fs*t_2_start)\n","idx_2_end = int(fs*t_2_end)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDwqcps_U1fd","outputId":"8fe70252-db13-46e6-9cf9-b9a65d5f0d80"},"outputs":[],"source":["all_data=[]\n","for fname in all_files:\n","  streams, header = pyxdf.load_xdf(fname)\n","  data = streams[0][\"time_series\"].T\n","  # crop data from second 1 to 6\n","  cropped_data_1 = data[:,idx_1_start:idx_1_end+1]\n","  cropped_data_2 = data[:,idx_2_start:idx_2_end+1]\n","  # print(fname)\n","  all_data.append(cropped_data_1)\n","  all_data.append(cropped_data_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYSG9z9Jx121","outputId":"2452cc98-2401-40af-8ed5-99456a4f6efd"},"outputs":[],"source":["len(all_data)\n","for data in all_data:\n","  print(data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpFDxQBkaiBF","outputId":"3d9781fa-829f-4c68-c59b-d939ed2c399a"},"outputs":[],"source":["# Combine into a 3D array\n","combined_array = np.stack(all_data, axis=0)\n","print(combined_array.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PkGuYF_Zqy4"},"outputs":[],"source":["eeg_data = combined_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsEhotDscDls"},"outputs":[],"source":["epochs = mne.EpochsArray(eeg_data, info, verbose=verbose, tmin=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_93FSvuIk5HI"},"outputs":[],"source":["# epochs.set_montage('standard_1020')\n","epochs.filter(1., None)\n","# epochs.apply_baseline(baseline=(-.250, 0)) # linear baseline correction\n","\n","epochs.event_id = event_id\n","epochs.events[:,2] = task_numbers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Jiwx0gwcFRc","outputId":"04426b48-ac9d-490a-d2ee-724342872e9b"},"outputs":[],"source":["epochs.filter(7.0, 32.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153},"id":"9sHtS94PcHuk","outputId":"ff130d48-6472-4061-d765-6b19d77ab787"},"outputs":[],"source":["epochs"]},{"cell_type":"markdown","metadata":{"id":"Np7cnSG_cFRe"},"source":["## Apply FBCSP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I78J6UJ2cFRe"},"outputs":[],"source":["verbose_clf = False # control output of FBCSP function\n","freqs_band = np.linspace(8, 32, 7) # filter bank choice\n","cv = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2HQG7uScFRj","outputId":"e48e0325-cdb7-4c6f-b92a-56f0921a6c81"},"outputs":[],"source":["freqs_band"]},{"cell_type":"markdown","metadata":{"id":"uROJ-K9_cFRj"},"source":["## FBCSP\n","The class must receive in input with the initialization a training set inside a dictionary. The keys of the dictionary must be the label of the two class and each element must be a numpy matrix of dimension \"n. trials x n. channels x n.samples\". The class must also receive the frequency sampling of the signal.\n","\n","FBCSP function original has a built-in random splitting so I didn't do a manual splitting here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCXlF9u_cFRj"},"outputs":[],"source":["data, labels = epochs.get_data(), epochs.events[:,-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OgWv59XPcFRj","outputId":"068586f5-c00d-4255-fe18-3472425d7647"},"outputs":[],"source":["print(data.shape)\n","print(labels.shape)\n","labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3F6HPHeqcFRk"},"outputs":[],"source":["data_dict = {'Right Grasp':  epochs['Right Grasp'].get_data(),\n","            'Right Release': epochs['Right Release'].get_data()}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jl_s79MMcFRk","outputId":"a4938c28-48a9-4d48-a024-8e5a8b798bde"},"outputs":[],"source":["epochs['Right Grasp'][0].get_data().shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auCt71lBcFRk","outputId":"0a6384d5-83a6-4b27-ff38-b0b07f3d9608"},"outputs":[],"source":["epochs.get_data()[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsJ5IDR6cFRk","outputId":"ed89a4d8-7a12-4245-fc07-ea2b67169a26"},"outputs":[],"source":["print(data_dict[\"Right Grasp\"].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcnWUHSMcFRk","outputId":"dd81fc3a-0c34-4f7f-e1d1-c3e30c29f7d0"},"outputs":[],"source":["data_dict[\"Right Grasp\"][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qSPkJjcYcFRl","outputId":"6e6bc77f-b682-486e-bd4f-000e82dd4923"},"outputs":[],"source":["fs = epochs.info['sfreq']\n","fs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSYaFkJ0cFRl"},"outputs":[],"source":["event_id = {'Right Grasp': 1, 'Right Release': 2, 'Baseline': 3}\n"]},{"cell_type":"markdown","metadata":{"id":"MFXC1cE7cFRl"},"source":["## FBCSP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSMsobSjcFRl","outputId":"7e95eb5d-2bc0-4a57-e7b9-577a3ccfd085"},"outputs":[],"source":["fbcsp_clf = FBCSP(data_dict, fs, freqs_band=freqs_band)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEZx1mWdcFRl"},"outputs":[],"source":["# epochs['Right Grasp'][0].get_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9VXBDuLcFRm"},"outputs":[],"source":["data_matrix = fbcsp_clf.tmp_data_matrix\n","labels = fbcsp_clf.tmp_label\n","# labels_dict = fbcsp_clf.tmp_label_dict\n","# labels_dict = fbcsp_clf.n_features_for_classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3raMeImcFRm","outputId":"073add79-979a-4411-fc45-8d37eeafa134"},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6q2ehIqcFRm"},"outputs":[],"source":["X = data_matrix\n","y = labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhjNR4gzcFRm","outputId":"ca761bb6-075e-47f0-966e-34638593cddc"},"outputs":[],"source":["print(data_matrix.shape)"]},{"cell_type":"markdown","metadata":{"id":"ffvkQ8z1cFRn"},"source":["## Normal Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2rnfS1dcFRn"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=labels,test_size=0.4, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZLTYlhhcFRn","outputId":"4d771087-ecd4-4733-cc84-27323db53ce9"},"outputs":[],"source":["print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhwAxP9xcFRo","outputId":"4f96e372-8364-42ba-ba8c-31acdd6b8047"},"outputs":[],"source":["print(y_train.shape)\n","print(y_train)\n","print(y_test.shape)\n","print(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EaIcq5icFRo","outputId":"39e81ef5-f3dd-47df-c191-190a3d169e99"},"outputs":[],"source":["print(type(X_train))\n","print(type(y_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iImZ9vLhcFRo","outputId":"75b2a542-24a2-4e42-de99-659bc1e63d72"},"outputs":[],"source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.metrics import accuracy_score\n","\n","lda_classifier = LDA()\n","lda_classifier.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kR4T3mQycFRo","outputId":"4d9ff2fa-9355-40d3-d030-b4526e92b17c"},"outputs":[],"source":["# Step 7: Evaluate the Model\n","y_pred = lda_classifier.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy * 100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0hODFNocFRo"},"outputs":[],"source":["kappa_scorer = sklearn.metrics.make_scorer(sklearn.metrics.cohen_kappa_score)\n","accuracy_scorer = sklearn.metrics.make_scorer(sklearn.metrics.accuracy_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kV9aXG84cFRp","outputId":"24bda75a-0dfa-4a18-abd3-65f8b1fad28a"},"outputs":[],"source":["# Accuracy Score\n","train_score = accuracy_scorer(lda_classifier, X_train, y_train)\n","test_score = accuracy_scorer(lda_classifier, X_test, y_test)\n","print(\"Accuracy Score on Training set: \", train_score)\n","print(\"Accuracy Score on Test set: \", test_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEvY1XeGcFRp","outputId":"fe5e30e6-028f-421b-95b3-54c82daab314"},"outputs":[],"source":["# Kappa Score\n","train_score = kappa_scorer(lda_classifier, X_train, y_train)\n","test_score = kappa_scorer(lda_classifier, X_test, y_test)\n","print(\"Kappa Score on Training set: \", train_score)\n","print(\"Kappa Score on Test set: \", test_score)\n"]},{"cell_type":"markdown","metadata":{"id":"XQw0AFAscFRp"},"source":["### All Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmfv5Yp3cFRp"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","# from xgboost import XGBClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HziEAda-cFRq"},"outputs":[],"source":["# Dictionary to hold models and their names\n","models = {\n","    'SVM': SVC(kernel='rbf', C=1, gamma='scale'),\n","    'Linear SVC': LinearSVC(max_iter=10000, random_state=42),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n","    'k-NN': KNeighborsClassifier(n_neighbors=5),\n","    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n","    'LDA': LinearDiscriminantAnalysis(),\n","    'Naive Bayes': GaussianNB(),\n","    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n","    'Decision Tree': DecisionTreeClassifier(random_state=42),\n","    'MLP Classifier': MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4x5RO0GcFRq","outputId":"dc3e693b-e7fc-4159-9323-573fe6d3ecb4"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=labels,test_size=0.3, random_state=42)\n","print(\"Train Shape: \", X_train.shape)\n","print(\"Test Shape: \", X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7pahY7jcFRq"},"outputs":[],"source":["# Dictionary to store the trained models and their accuracies\n","# trained_models = {}\n","# model_accuracies = {}\n","\n","# # Train and evaluate each model\n","# for name, model in models.items():\n","#     model.fit(X_train, y_train)  # Train the model\n","#     y_pred = model.predict(X_test)  # Predict on test data\n","#     accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n","#     print(f'{name} Accuracy: {accuracy * 100:.2f}%')\n","\n","#     # Save the trained model to the dictionary\n","#     trained_models[name] = model\n","#     # Save the accuracy to the dictionary\n","#     model_accuracies[name] = accuracy * 100\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqhDwLp2cFRr"},"outputs":[],"source":["# # Find the model with the highest accuracy\n","# best_model_name = max(model_accuracies, key=model_accuracies.get)\n","# max_accuracy = model_accuracies[best_model_name]\n","\n","# # Print the model name and its maximum accuracy\n","# print(f'Best Model: {best_model_name} with Accuracy: {max_accuracy:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"KbLT0hp7cFRr"},"source":["## StratifiedKFold Cross Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMt9wavmcFRr"},"outputs":[],"source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.metrics import accuracy_score\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jrkave_rcFRr"},"outputs":[],"source":["X = data_matrix\n","y = labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NekUg-KTcFRs","outputId":"f109c360-2adc-4def-e161-1345e8b0dd46"},"outputs":[],"source":["print(X.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eU639afVcFRs","outputId":"9cb65e9d-0d5a-4682-854c-868fdc97ba64"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=labels,test_size=0.3, random_state=42)\n","print(\"Train Shape: \", X_train.shape)\n","print(\"Test Shape: \", X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvj0KwSCcFRt"},"outputs":[],"source":["# # Define the LDA classifier\n","# cv_lda_classifier = LDA()\n","\n","# # Use StratifiedKFold to maintain class distribution in each fold\n","# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=43)\n","\n","# # Perform cross-validation and compute accuracy for each fold\n","# cv_scores = cross_val_score(cv_lda_classifier, X, y, cv=kf, scoring='accuracy')\n","# # Print cross-validation scores\n","# print(f'Cross-validation scores for each fold: {cv_scores}')\n","# print(f'Average cross-validation accuracy: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1iDXaAEWcFRt","outputId":"f82c6a9d-866c-4026-d411-ccfe65d7aa62"},"outputs":[],"source":["# Dictionary to store the trained models and their accuracies\n","trained_models = {}\n","model_accuracies = {}\n","cv_results = {}\n","kappa_results = {}\n","\n","# Variable to track the best cross-validation score and corresponding model name\n","best_cv_score = 0\n","best_cv_model_name = \"\"\n","\n","# Train and evaluate each model\n","for name, model in models.items():\n","    model.fit(X_train, y_train)  # Train the model\n","    y_pred = model.predict(X_test)  # Predict on test data\n","    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n","    print(f'{name} Accuracy: {accuracy * 100:.2f}%')\n","\n","    # Kappa Score\n","    kappa_score = kappa_scorer(lda_classifier, X_test, y_test)\n","    print(\"Kappa Score on Test set: \", kappa_score)\n","\n","    # Save the trained model to the dictionary\n","    trained_models[name] = model\n","    # Save the accuracy to the dictionary\n","    # model_accuracies[name] = accuracy * 100\n","    model_accuracies[name] = accuracy\n","    # kappa_results[name] = kappa_score * 100\n","    kappa_results[name] = kappa_score\n","\n","    # Perform Stratified K-Fold cross-validation\n","    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=43)\n","    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n","    cv_results[name] = cv_scores\n","\n","    # Check if this model has the best cross-validation score\n","    if cv_scores.mean() > best_cv_score:\n","        best_cv_score = cv_scores.mean()\n","        best_cv_model_name = name\n","\n","    # Print cross-validation results\n","    print(f'Cross-validation scores for {name}: {cv_scores}')\n","    print(f'Average cross-validation accuracy for {name}: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}')\n","\n","    print(\"--\"*50)"]},{"cell_type":"markdown","metadata":{"id":"Danl2PB-cFRt"},"source":["## Best Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDAPB7ducFRt","outputId":"79070202-91b5-42b1-8a37-9f672a266a2f"},"outputs":[],"source":["# Print the model with the highest average cross-validation score\n","print(f'Best Model based on cross-validation: {best_cv_model_name} with Average CV Accuracy: {best_cv_score:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-uCpDPGcFRu","outputId":"479f9cf0-f17f-4c5c-ac2a-304d7a987387"},"outputs":[],"source":["# Find the model with the highest test set accuracy\n","best_model_name = max(model_accuracies, key=model_accuracies.get)\n","max_accuracy = model_accuracies[best_model_name]\n","print(f'Best Model based on test accuracy: {best_model_name} with Accuracy: {max_accuracy:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xC6TgS82cFRu","outputId":"98fd2be5-379b-449a-efc1-cf2a1189ab19"},"outputs":[],"source":["# Find the model with the highest test set accuracy\n","best_kappa_model_name = max(kappa_results, key=kappa_results.get)\n","max_kappa = kappa_results[best_kappa_model_name]\n","print(f'Best Model based on test Kappa : {best_kappa_model_name} with Kappa: {max_kappa:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uf296qDjcFRu"},"outputs":[],"source":["# # Optionally, you can save the best model for later use\n","# best_model = trained_models[best_model_name]\n","# joblib.dump(best_model, f'{best_model_name}_model.joblib')\n","\n","# To load and use the best model later\n","# loaded_best_model = joblib.load(f'{best_model_name}_model.joblib')\n","# predictions_transformed = loaded_best_model.predict(new_data)  # Replace 'new_data' with your actual data\n","# predictions = label_encoder.inverse_transform(predictions_transformed)"]},{"cell_type":"markdown","metadata":{},"source":["## Stacking"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris\n","from sklearn.metrics import accuracy_score\n","\n","\n","# Define base models\n","base_models = [\n","    ('svc', SVC(kernel='rbf', probability=True)),\n","    # ('linear_svc', LinearSVC(max_iter=10000)),\n","    ('log_reg', LogisticRegression(max_iter=10000)),\n","    ('lda', LinearDiscriminantAnalysis()),\n","    ('extra_trees', ExtraTreesClassifier(n_estimators=100, random_state=42)),\n","    ('mlp', MLPClassifier(max_iter=1000, random_state=42))\n","]\n","\n","# Define meta-learner\n","meta_learner = LogisticRegression()\n","\n","# Initialize and train the stacking model\n","stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner)\n","stacking_model.fit(X_train, y_train)\n","\n","# Make predictions and evaluate\n","y_pred = stacking_model.predict(X_test)\n","print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print accuracy\n","accuracy_stack = accuracy_score(y_test, y_pred)\n","print(\"Accuracy for stackL: \", accuracy_stack)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Kappa Score\n","kappa_score = kappa_scorer(stacking_model, X_test, y_test)\n","print(\"Kappa Score on Test set: \", kappa_score)"]},{"cell_type":"markdown","metadata":{},"source":["## My Stacking"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris\n","from sklearn.metrics import accuracy_score\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load pre-trained models (replace with your own paths)\n","with open('magdy\\magdy_best_linear_svm.pkl', 'rb') as f:\n","    svc = pickle.load(f)\n","\n","with open('magdy\\magdy_best_linear_svc.pkl', 'rb') as f:\n","    linear_svc = pickle.load(f)\n","\n","with open('magdy\\magdy_best_lr.pkl', 'rb') as f:\n","    log_reg = pickle.load(f)\n","\n","with open('magdy\\magdy_best_lda.pkl', 'rb') as f:\n","    lda = pickle.load(f)\n","\n","with open('magdy\\magdy_best_extra_trees.pkl', 'rb') as f:\n","    extra_trees = pickle.load(f)\n","\n","with open('magdy\\magdy_best_linear_mlp.pkl', 'rb') as f:\n","    mlp = pickle.load(f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = {}\n","\n","models['LDA'] = lda\n","models['MLP'] = mlp\n","models['Linear_SVC'] = linear_svc\n","models['Linear_SVM'] = svc\n","models['LR'] = log_reg\n","# models['extra_trees'] = extra_trees"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define base models with preprocessing (if needed)\n","base_models = [\n","    ('svc', make_pipeline(StandardScaler(), svc)),\n","    ('linear_svc', make_pipeline(StandardScaler(), linear_svc)),\n","    ('log_reg', make_pipeline(StandardScaler(), log_reg)),\n","    ('lda', lda),\n","    # ('extra_trees', extra_trees),\n","    ('mlp', make_pipeline(StandardScaler(), mlp))\n","]\n","\n","# Define meta-learner\n","meta_learner = LogisticRegression(max_iter=10000)\n","\n","# Initialize and train the stacking model\n","stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner, cv=5)\n","stacking_model.fit(X_train, y_train)\n","\n","# Make predictions and evaluate\n","y_pred = stacking_model.predict(X_test)\n","print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Kappa Score\n","kappa_score = kappa_scorer(stacking_model, X_test, y_test)\n","print(\"Kappa Score on Test set: \", kappa_score)"]},{"cell_type":"markdown","metadata":{},"source":["## My Stacking Manual"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from collections import Counter\n","\n","# # Dictionary to hold predictions from each model\n","# predictions = {}\n","\n","# # Predict using each model and store the results\n","# for model_name, model in models.items():\n","#     prediction = model.predict(X_test[0])\n","#     predictions[model_name] = int(prediction[0])\n","#     print(f\"{model_name}: Predicted class: {prediction[0]}\")\n","\n","# # Get the mode of the classifications\n","# prediction_counts = Counter(predictions.values())\n","# if prediction_counts[1] > prediction_counts[2]:\n","#     final_prediction = \"Grasp\"\n","# elif prediction_counts[1] < prediction_counts[2]:\n","#     final_prediction = \"Release\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = {}\n","\n","models['LDA'] = lda\n","models['MLP'] = mlp\n","# models['Linear_SVC'] = linear_svc\n","models['Linear_SVM'] = svc\n","models['LR'] = log_reg\n","models['extra_trees'] = extra_trees"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter\n","\n","# Function to make predictions using each model and get the mode of the predictions\n","def predict_ensemble(models, X):\n","    predictions = {}\n","    for model_name, model in models.items():\n","        prediction = model.predict(X)\n","        predictions[model_name] = int(prediction[0])\n","    \n","    # Get the mode of the classifications\n","    prediction_counts = Counter(predictions.values())\n","    final_prediction = prediction_counts.most_common(1)[0][0]\n","    return final_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# List to hold final predictions\n","final_predictions = []\n","\n","# Make predictions on the test data\n","for i in range(X_test.shape[0]):\n","    final_prediction = predict_ensemble(models, [X_test[i]])\n","    final_predictions.append(final_prediction)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, final_predictions)\n","print(f'Ensemble Model Accuracy: {accuracy}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = {}\n","for model_name, model in models.items():\n","    prediction = model.predict(X)\n","    predictions[model_name] = int(prediction[0])\n","\n","# Get the mode of the classifications\n","prediction_counts = Counter(predictions.values())\n","final_prediction = prediction_counts.most_common(1)[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import accuracy_score, cohen_kappa_score\n","\n","# Calculate Cohen's Kappa score\n","kappa_score = cohen_kappa_score(y_test, final_predictions)\n","print(f'Cohen\\'s Kappa Score: {kappa_score}')"]},{"cell_type":"markdown","metadata":{},"source":["## Soft Voting"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import VotingClassifier\n","\n","# Create a soft voting classifier\n","voting_clf = VotingClassifier(estimators=[\n","    ('svc', svc),\n","    ('linear_svc', linear_svc),\n","    ('log_reg', log_reg),\n","    ('lda', lda),\n","    # ('extra_trees', extra_trees),\n","    ('mlp', mlp)\n","], voting='hard')\n","\n","# Fit the classifier on the training data\n","voting_clf.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions on the test data\n","y_pred = voting_clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Ensemble Model Accuracy: {accuracy}')\n","\n","# Calculate Cohen's Kappa score\n","kappa_score = cohen_kappa_score(y_test, y_pred)\n","print(f'Cohen\\'s Kappa Score: {kappa_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Soft Voting "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.neural_network import MLPClassifier\n","\n","# Define the individual classifiers\n","svc = SVC(probability=True)\n","linear_svc = SVC(kernel='linear', probability=True)\n","log_reg = LogisticRegression()\n","lda = LDA()\n","mlp = MLPClassifier()\n","\n","# Create a soft voting classifier\n","voting_clf = VotingClassifier(estimators=[\n","    ('svc', svc),\n","    ('linear_svc', linear_svc),\n","    ('log_reg', log_reg),\n","    ('lda', lda),\n","    ('mlp', mlp)\n","], voting='soft')\n","\n","# Fit the classifier on the training data\n","voting_clf.fit(X_train, y_train)\n","\n","# Predict on new data\n","y_pred = voting_clf.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Ensemble Model Accuracy: {accuracy}')\n","\n","# Calculate Cohen's Kappa score\n","kappa_score = cohen_kappa_score(y_test, y_pred)\n","print(f'Cohen\\'s Kappa Score: {kappa_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Tnk_HkivcFRv"},"source":["## Trial Prediction Time"]},{"cell_type":"markdown","metadata":{},"source":["## Soft Voting "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.neural_network import MLPClassifier\n","\n","# Define the individual classifiers\n","svc = SVC(probability=True)\n","linear_svc = SVC(kernel='linear', probability=True)\n","log_reg = LogisticRegression()\n","lda = LDA()\n","mlp = MLPClassifier()\n","\n","# Create a soft voting classifier\n","voting_clf = VotingClassifier(estimators=[\n","    ('svc', svc),\n","    ('linear_svc', linear_svc),\n","    ('log_reg', log_reg),\n","    ('lda', lda),\n","    ('mlp', mlp)\n","], voting='soft')\n","\n","# Fit the classifier on the training data\n","voting_clf.fit(X_train, y_train)\n","\n","# Predict on new data\n","y_pred = voting_clf.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Ensemble Model Accuracy: {accuracy}')\n","\n","# Calculate Cohen's Kappa score\n","kappa_score = cohen_kappa_score(y_test, y_pred)\n","print(f'Cohen\\'s Kappa Score: {kappa_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUTQ9kN1cFRv","outputId":"9fe44ac9-88c5-42a6-89a8-62f0e8f3b52b"},"outputs":[],"source":["epochs['Right Grasp'][0].get_data().shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaJj1A_NcFRv"},"outputs":[],"source":["# fbcsp_clf.evaluateTrial(epochs['Right Grasp'][0].get_data())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tgk_u3X2cFRv","outputId":"f583783e-28e2-4e72-b5cb-5f1506587129"},"outputs":[],"source":["trial_features = fbcsp_clf.extractTrialFeatures(epochs['Right Grasp'][0].get_data())\n","# print(trial_features.shape)\n","trial_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaHcqJztcFRw","outputId":"53b81aad-bc83-4811-f3da-0dd78b8891dd"},"outputs":[],"source":["trained_models[\"LDA\"].predict(trial_features)\n","# LDA.predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28bq-M_lcFRw","outputId":"9316e3f1-5452-4afa-f35f-64bdf874974e"},"outputs":[],"source":["trained_models[\"LDA\"].predict_proba(trial_features)"]},{"cell_type":"markdown","metadata":{"id":"seoXhkDycFRw"},"source":["### Release"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbAFaYY7cFRw"},"outputs":[],"source":["# fbcsp_clf.evaluateTrial(epochs['Right Release'][9].get_data())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psr4IJsKcFRw","outputId":"eb0afc25-389e-4bae-9534-4995d57ee70b"},"outputs":[],"source":["trial_features = fbcsp_clf.extractTrialFeatures(epochs['Right Release'][9].get_data())\n","# print(trial_features.shape)\n","trial_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZMrhBhycFRw","outputId":"856191b2-f320-478b-ee63-c14a4a5fe3e0"},"outputs":[],"source":["trained_models[\"LDA\"].predict(trial_features)\n"]},{"cell_type":"markdown","metadata":{"id":"BgezQhuocFRx"},"source":["## Save Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bk1HUbj2cFRx"},"outputs":[],"source":["import pickle\n","\n","# Save the FBCSP to a file\n","with open(sub_name+'_fbcsp_clf.pkl', 'wb') as file:\n","    pickle.dump(fbcsp_clf, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ddx4uEK9cFRx"},"outputs":[],"source":["# Save the trained model to a file\n","with open(sub_name+'_LDA_clf.pkl', 'wb') as file:\n","    pickle.dump(trained_models[\"LDA\"], file)"]},{"cell_type":"markdown","metadata":{"id":"oHvK2ulrcFRy"},"source":["## Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TP9ruNHzcFRz"},"outputs":[],"source":["# Load the FBCSP from the file\n","with open('fbcsp_clf_sherif.pkl', 'rb') as file:\n","    loaded_fbcsp_clf = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_O96iX4FcFRz"},"outputs":[],"source":["# Load the trained model from the file\n","with open('LDA_clf_sherif.pkl', 'rb') as file:\n","    loaded_LDA_clf = pickle.load(file)"]},{"cell_type":"markdown","metadata":{"id":"Vm263ZalcFRz"},"source":["## Trial Prediction with loaded models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DtlSe6qcFR0","outputId":"ec22b2f0-c654-4783-d2e4-0a9eee784c4c"},"outputs":[],"source":["trial_features = loaded_fbcsp_clf.extractTrialFeatures(epochs['Right Release'][9].get_data())\n","# print(trial_features.shape)\n","trial_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggjNBmOkcFR0","outputId":"b6be0123-5348-46e0-f4fb-10c42a8ac577"},"outputs":[],"source":["loaded_LDA_clf.predict(trial_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgO0eKcycFR0","outputId":"91109fd1-ccc3-4502-d505-e1ff4b924219"},"outputs":[],"source":["prediction = loaded_LDA_clf.predict(trial_features)\n","prediction[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"II0O7LqRcFR1","outputId":"c0934e22-0aff-448e-ee47-dd70c3261407"},"outputs":[],"source":["type(prediction[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPb7Rhu6cFR1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"1WD42QTOcFR1"},"source":["# Grid Search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ac6cNAjVcFR1"},"outputs":[],"source":["# # Dictionary to hold models and their names\n","# models = {\n","#     'SVM': SVC(kernel='rbf', C=1, gamma='scale'),\n","#     'Linear SVC': LinearSVC(max_iter=10000, random_state=42),\n","#     'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n","#     'k-NN': KNeighborsClassifier(n_neighbors=5),\n","#     'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n","#     'LDA': LinearDiscriminantAnalysis(),\n","#     'Naive Bayes': GaussianNB(),\n","#     'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n","#     'Decision Tree': DecisionTreeClassifier(random_state=42),\n","#     'MLP Classifier': MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42),\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S60F2xD9cFR1"},"outputs":[],"source":["from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"nWx3m0WgcFR1"},"source":["## SVM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUNMSbKXcFR2"},"outputs":[],"source":["# Define the parameter grid\n","param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],\n","    'gamma': ['scale', 'auto', 1, 0.1, 0.01, 0.001],\n","    'kernel': ['linear', 'rbf', 'poly'],\n","    'tol': [1e-4, 1e-3, 1e-2],\n","    'max_iter': [1000, 2000, 3000],\n","    'degree': [2, 3, 4],  # Only used for 'poly' kernel\n","}\n","\n","# Initialize the SVM classifier\n","svm = SVC()\n","\n","# Initialize the GridSearchCV object\n","grid_search_svm = GridSearchCV(svm, param_grid, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_svm.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters found: \", grid_search_svm.best_params_)\n","print(\"Best estimator: \", grid_search_svm.best_estimator_)\n","\n","\n","\n","# Use the best parameters to fit the model\n","best_linear_svm = grid_search_svm.best_estimator_\n","\n","# Predict using the best model\n","y_pred_svm = best_linear_svm.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for SVM:\\n\", classification_report(y_test, y_pred_svm))\n","\n","# Print accuracy\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","print(\"Accuracy for SVM: \", accuracy_svm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teKJtQsQcFR2"},"outputs":[],"source":["# Save the best LDA model\n","with open(sub_name+'_best_linear_svm.pkl', 'wb') as file:\n","    pickle.dump(best_linear_svm, file)"]},{"cell_type":"markdown","metadata":{"id":"VQJPK707cFR2"},"source":["- Best parameters found:  {'C': 1, 'degree': 2, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 1000, 'tol': 0.01}\n","- Best estimator:  SVC(C=1, degree=2, gamma=0.01, max_iter=1000, tol=0.01)\n","- Accuracy: 0.69"]},{"cell_type":"markdown","metadata":{"id":"QjooXCXncFR2"},"source":["## MLP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gs4As5M6cFR3","outputId":"b430f91e-2ec0-459b-ef3c-ee5941797450"},"outputs":[],"source":["# Define the parameter grid\n","param_grid_mlp = {\n","    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n","    'activation': ['tanh', 'relu'],\n","    'solver': ['sgd', 'adam'],\n","    'alpha': [0.0001, 0.05],\n","    'learning_rate': ['constant','adaptive'],\n","}\n","\n","# Initialize the MLP classifier\n","mlp = MLPClassifier(max_iter=100)\n","\n","# Initialize the GridSearchCV object\n","grid_search_mlp = GridSearchCV(mlp, param_grid_mlp, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_mlp.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters for MLP found: \", grid_search_mlp.best_params_)\n","print(\"Best MLP estimator: \", grid_search_mlp.best_estimator_)\n","\n","\n","\n","# Use the best parameters to fit the model\n","best_linear_mlp = grid_search_mlp.best_estimator_\n","\n","# Predict using the best model\n","y_pred_mlp = best_linear_mlp.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for MLP:\\n\", classification_report(y_test, y_pred_mlp))\n","\n","# Print accuracy\n","accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n","print(\"Accuracy for MLP: \", accuracy_mlp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3g5XEEM3cFR3"},"outputs":[],"source":["# Save the best LDA model\n","with open(sub_name+'_best_linear_mlp.pkl', 'wb') as file:\n","    pickle.dump(best_linear_mlp, file)"]},{"cell_type":"markdown","metadata":{"id":"DhCYeUhscFR5"},"source":["- Best parameters for MLP found:  {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n","- Best MLP estimator:  MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 50, 50),\n","              learning_rate='adaptive', max_iter=100, solver='sgd')\n","- Accuracy: 0.7"]},{"cell_type":"markdown","metadata":{"id":"75A7MQiZcFR5"},"source":["## LDA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBZHtlIucFR5","outputId":"c5775a21-85c9-47e5-bf5c-c61c9873fb8b"},"outputs":[],"source":["# Define the parameter grid\n","param_grid_lda = {\n","    'solver': ['svd', 'lsqr', 'eigen'],\n","    'priors': [None],\n","    'n_components': [None, 1, 2],\n","    'store_covariance': [False, True],\n","    'tol': [0.0001, 1e-4, 1e-3, 1e-2],\n","    'covariance_estimator': [None]\n","}\n","\n","# Initialize the LDA classifier\n","lda = LinearDiscriminantAnalysis()\n","\n","# Initialize the GridSearchCV object\n","grid_search_lda = GridSearchCV(lda, param_grid_lda, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_lda.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters for LDA found: \", grid_search_lda.best_params_)\n","print(\"Best LDA estimator: \", grid_search_lda.best_estimator_)\n","\n","\n","\n","# Use the best parameters to fit the model\n","best_lda = grid_search_lda.best_estimator_\n","\n","# Predict using the best model\n","y_pred_lda = best_lda.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for LDA:\\n\", classification_report(y_test, y_pred_lda))\n","\n","# Print accuracy\n","accuracy_lda = accuracy_score(y_test, y_pred_lda)\n","print(\"Accuracy for LinearSVC: \", accuracy_lda)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PYeM9DyvcFR5"},"outputs":[],"source":["# Save the best LDA model\n","with open(sub_name+'_best_lda.pkl', 'wb') as file:\n","    pickle.dump(best_lda, file)"]},{"cell_type":"markdown","metadata":{"id":"Vp-IvXGZcFR6"},"source":["- Best parameters for LDA found:  {'covariance_estimator': None, 'n_components': None, 'priors': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}\n","- Best LDA estimator:  LinearDiscriminantAnalysis()\n","- Accuracy: 0.77"]},{"cell_type":"markdown","metadata":{"id":"3DkxvGSdcFR6"},"source":["## Linear SVC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJsOLtp0cFR6","outputId":"b2e2890a-8dda-490c-dbe6-0e566675c1a3"},"outputs":[],"source":["# Define the parameter grid\n","param_grid_linear_svc = {\n","    'penalty': ['l2'],\n","    'loss': ['squared_hinge'],\n","    'dual': [True, False],  # must be True if 'penalty' is 'l1'\n","    'tol': [1e-4, 1e-3, 1e-2],\n","    'class_weight': [None, 'balanced'],\n","    'verbose': [0, 1],\n","    'random_state': [None, 42],\n","    'max_iter': [1000, 2000, 3000]\n","}\n","\n","# Initialize the LinearSVC classifier\n","linear_svc = LinearSVC()\n","\n","# Initialize the GridSearchCV object\n","grid_search_linear_svc = GridSearchCV(linear_svc, param_grid_linear_svc, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_linear_svc.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters for LinearSVC found: \", grid_search_linear_svc.best_params_)\n","print(\"Best LinearSVC estimator: \", grid_search_linear_svc.best_estimator_)\n","\n","\n","\n","# Use the best parameters to fit the model\n","best_linear_svc = grid_search_linear_svc.best_estimator_\n","\n","# Predict using the best model\n","y_pred_linear_svc = best_linear_svc.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for LinearSVC:\\n\", classification_report(y_test, y_pred_linear_svc))\n","\n","# Print accuracy\n","accuracy_linear_svc = accuracy_score(y_test, y_pred_linear_svc)\n","print(\"Accuracy for LinearSVC: \", accuracy_linear_svc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmB02bVvcFR6"},"outputs":[],"source":["# Save the best LDA model\n","with open(sub_name+'_best_linear_svc.pkl', 'wb') as file:\n","    pickle.dump(best_linear_svc, file)"]},{"cell_type":"markdown","metadata":{"id":"_VDHikTAcFR6"},"source":["- Best parameters for LinearSVC found:  {'class_weight': None, 'dual': True, 'loss': 'squared_hinge', 'max_iter': 1000, 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n","- Best LinearSVC estimator:  LinearSVC(dual=True)\n","- Accuracy: 0.77"]},{"cell_type":"markdown","metadata":{"id":"t9E3LsobcFR7"},"source":["## LR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SqmkLbQFcFR7","outputId":"672bc51e-d55c-4c20-f804-6926c376a6da"},"outputs":[],"source":["# Define the parameter grid\n","param_grid_lr = {\n","    'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n","    'tol': [1e-4, 1e-3, 1e-2],\n","    'intercept_scaling': [1, 10, 100],\n","    'class_weight': [None, 'balanced'],\n","    'random_state': [None, 42],\n","    'max_iter': [1000, 800, 500, 300, 200, 100],\n","    'multi_class': ['auto', 'ovr', 'multinomial'],\n","    'warm_start': [False, True],\n","    'n_jobs': [None, -1],\n","}\n","\n","\n","# Initialize the Logistic Regression classifier\n","lr = LogisticRegression(max_iter=1000)\n","\n","# Initialize the GridSearchCV object\n","grid_search_lr = GridSearchCV(lr, param_grid_lr, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_lr.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters for Logistic Regression found: \", grid_search_lr.best_params_)\n","print(\"Best Logistic Regression estimator: \", grid_search_lr.best_estimator_)\n","\n","\n","\n","# Use the best parameters to fit the model\n","best_lr = grid_search_lr.best_estimator_\n","\n","# Predict using the best model\n","y_pred_lr = best_lr.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for LinearSVC:\\n\", classification_report(y_test, y_pred_lr))\n","\n","# Print accuracy\n","accuracy_lr = accuracy_score(y_test, y_pred_lr)\n","print(\"Accuracy for LinearSVC: \", accuracy_lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AHVHIbOcFR7"},"outputs":[],"source":["# Save the best LDA model\n","with open(sub_name+'_best_lr.pkl', 'wb') as file:\n","    pickle.dump(best_lr, file)"]},{"cell_type":"markdown","metadata":{"id":"RujLHkEbcFR8"},"source":["- Best parameters for Logistic Regression found:  {'class_weight': None, 'intercept_scaling': 1, 'max_iter': 1000, 'multi_class': 'ovr', 'n_jobs': -1, 'random_state': None, 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n","- Best Logistic Regression estimator:  LogisticRegression(max_iter=1000, multi_class='ovr', n_jobs=-1, solver='saga',\n","                   tol=0.01)\n","- Accuracy: 0.77"]},{"cell_type":"markdown","metadata":{"id":"_i8y3StIcFR8"},"source":["## Extra Trees"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW0ksnn1cFR8","outputId":"38d0016e-1d3f-4e9a-c811-bf31b8024304"},"outputs":[],"source":["from sklearn.ensemble import ExtraTreesClassifier\n","\n","# Define the parameter grid\n","param_grid_extra_trees = {\n","    'n_estimators': [50, 100, 200],\n","#     'criterion': ['gini', 'entropy', 'log_loss'], no\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","#     'min_samples_leaf': [1, 2, 4], no\n","#     'min_weight_fraction_leaf': [0.0, 0.1, 0.2], no\n","    'max_features': ['auto', 'sqrt', 'log2'],\n","    'max_leaf_nodes': [None, 10, 20, 30],\n","#     'min_impurity_decrease': [0.0, 0.1, 0.2], no\n","#     'bootstrap': [False, True],\n","#     'oob_score': [False, True],\n","#     'n_jobs': [None, -1],\n","#     'random_state': [None, 42], no\n","#     'verbose': [0, 1],\n","#     'warm_start': [False, True],\n","#     'class_weight': [None, 'balanced'],\n","    'ccp_alpha': [0.0, 0.1, 0.2],\n","    'max_samples': [None, 0.5, 0.7]\n","\n","#     'n_estimators': [50, 100, 200],\n","#     'max_features': ['auto', 'sqrt', 'log2'],\n","#     'max_depth': [None, 10, 20, 30],\n","#     'min_samples_split': [2, 5, 10]\n","}\n","\n","# Initialize the Extra Trees Classifier\n","extra_trees = ExtraTreesClassifier()\n","\n","# Initialize the GridSearchCV object\n","grid_search_extra_trees = GridSearchCV(extra_trees, param_grid_extra_trees, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_extra_trees.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters for Extra Trees found: \", grid_search_extra_trees.best_params_)\n","print(\"Best Extra Trees estimator: \", grid_search_extra_trees.best_estimator_)\n","\n","\n","\n","# Use the best parameters to fit the model\n","best_extra_trees = grid_search_extra_trees.best_estimator_\n","\n","# Predict using the best model\n","y_pred_extra_trees = best_extra_trees.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for LinearSVC:\\n\", classification_report(y_test, y_pred_extra_trees))\n","\n","# Print accuracy\n","accuracy_extra_trees = accuracy_score(y_test, y_pred_extra_trees)\n","print(\"Accuracy for LinearSVC: \", accuracy_extra_trees)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QFogToncFR8"},"outputs":[],"source":["# Save the best LDA model\n","with open(sub_name+'_best_extra_trees.pkl', 'wb') as file:\n","    pickle.dump(best_extra_trees, file)"]},{"cell_type":"markdown","metadata":{"id":"uSCOXkNVcFR8"},"source":["- Best parameters for Extra Trees found:  {'ccp_alpha': 0.0, 'max_depth': 30, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'min_samples_split': 5, 'n_estimators': 50}\n","- Best Extra Trees estimator:  ExtraTreesClassifier(max_depth=30, max_leaf_nodes=10, min_samples_split=5,\n","                     n_estimators=50)\n","- Accuracy: 0.7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2KCFTpFcFR9"},"outputs":[],"source":["# from sklearn.ensemble import ExtraTreesClassifier 70\n","\n","# Define the parameter grid\n","param_grid_extra_trees = {\n","    'n_estimators': [50, 100, 200],\n","#     'criterion': ['gini', 'entropy', 'log_loss'], no\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","#     'min_samples_leaf': [1, 2, 4], no\n","#     'min_weight_fraction_leaf': [0.0, 0.1, 0.2], no\n","    'max_features': ['auto', 'sqrt', 'log2'],\n","    'max_leaf_nodes': [None, 10, 20, 30],\n","#     'min_impurity_decrease': [0.0, 0.1, 0.2],\n","#     'bootstrap': [False, True],\n","#     'oob_score': [False, True],\n","#     'n_jobs': [None, -1],\n","#     'random_state': [None, 42],\n","#     'verbose': [0, 1],\n","#     'warm_start': [False, True],\n","#     'class_weight': [None, 'balanced'],\n","    'ccp_alpha': [0.0, 0.1, 0.2],\n","#     'max_samples': [None, 0.5, 0.7]\n","\n","#     'n_estimators': [50, 100, 200],\n","#     'max_features': ['auto', 'sqrt', 'log2'],\n","#     'max_depth': [None, 10, 20, 30],\n","#     'min_samples_split': [2, 5, 10]\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmtiZ-CUcFR9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92rXncKKcFR9"},"outputs":[],"source":["# Import necessary libraries\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load the dataset\n","data = load_iris()\n","X = data.data\n","y = data.target\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the parameter grid\n","param_grid_linear_svc = {\n","    'C': [0.1, 1, 10, 100],\n","    'max_iter': [1000, 2000, 3000]\n","}\n","\n","# Initialize the LinearSVC classifier\n","linear_svc = LinearSVC()\n","\n","# Initialize the GridSearchCV object\n","grid_search_linear_svc = GridSearchCV(linear_svc, param_grid_linear_svc, refit=True, verbose=2, cv=5)\n","\n","# Fit the model\n","grid_search_linear_svc.fit(X_train, y_train)\n","\n","# Print the best parameters and estimator\n","print(\"Best parameters for LinearSVC found: \", grid_search_linear_svc.best_params_)\n","print(\"Best LinearSVC estimator: \", grid_search_linear_svc.best_estimator_)\n","\n","# Use the best parameters to fit the model\n","best_linear_svc = grid_search_linear_svc.best_estimator_\n","\n","# Predict using the best model\n","y_pred_linear_svc = best_linear_svc.predict(X_test)\n","\n","# Print classification report\n","print(\"Classification report for LinearSVC:\\n\", classification_report(y_test, y_pred_linear_svc))\n","\n","# Print accuracy\n","accuracy_linear_svc = accuracy_score(y_test, y_pred_linear_svc)\n","print(\"Accuracy for LinearSVC with best parameters: \", accuracy_linear_svc)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
